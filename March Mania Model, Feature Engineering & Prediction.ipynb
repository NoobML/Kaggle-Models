{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91497,"databundleVersionId":11165145,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"\n\n# **March Machine Learning Mania 2025 - Model Explanation**  \n\n## **Overview**  \nThis notebook is designed for predicting the outcomes of NCAA basketball tournament games. It processes historical game data, extracts features, and trains a machine learning model (Random Forest) to make predictions based on team statistics.  \n\n## **Dataset Description**  \nThe dataset comes from Kaggle's *March Machine Learning Mania 2025* competition. It contains historical game results, team details, tournament seeds, and various match statistics for men's and women's NCAA basketball teams.  \n\n## **Steps in the Notebook**  \n\n### **1. Importing Libraries**  \n- Uses `numpy` and `pandas` for data manipulation.  \n- `sklearn` for machine learning tasks.  \n- `optuna` for hyperparameter tuning.  \n- `glob` to load multiple CSV files dynamically.  \n\n### **2. Data Loading**  \n- Reads multiple CSV files from the dataset folder.  \n- Stores each file in a dictionary for easy access.  \n\n### **3. Data Preprocessing**  \n- Extracts key tables for men’s and women’s tournaments.  \n- Merges relevant datasets like regular-season results, NCAA tournament results, and team seeds.  \n- Converts categorical tournament seed rankings into numerical values.  \n\n### **4. Feature Engineering**  \n- Creates unique game identifiers based on season and team matchups.  \n- Computes important features, such as:  \n  - **Seed Difference**: Difference between two teams' NCAA tournament seed rankings.  \n  - **Match Statistics Aggregation**: Summarizes stats (sum, mean, median, max, min, std, skew) from past games.  \n  - **Game Location Encoding**: Converts home, away, and neutral game locations into numeric values.  \n  - **Target Variable (`Pred`)**: Indicates whether the first team won the game.  \n\n### **5. Data Filtering**  \n- Filters the dataset to keep only NCAA tournament games for training the model.  \n\n## **Purpose of the Notebook**  \nThis notebook sets up a machine learning pipeline for predicting NCAA tournament match outcomes based on past performance metrics and team seeds. It prepares a structured dataset, which can be used to train a machine learning model like **Random Forest**.  \n\n**Kaggle Profile Link:** https://www.kaggle.com/mushei\n\n**Kaggle Competition Link:** https://www.kaggle.com/competitions/march-machine-learning-mania-2025/data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nimport optuna\nfrom sklearn.model_selection import KFold\nfrom sklearn.base import clone\nimport glob\nimport warnings \n\nwarnings.filterwarnings('ignore')\npd.set_option(\"display.max_rows\", None)\npd.set_option(\"display.max_columns\", None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:00:32.581798Z","iopub.execute_input":"2025-03-02T12:00:32.582197Z","iopub.status.idle":"2025-03-02T12:00:32.586779Z","shell.execute_reply.started":"2025-03-02T12:00:32.582171Z","shell.execute_reply":"2025-03-02T12:00:32.586091Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"Path = \"/kaggle/input/march-machine-learning-mania-2025/*.csv\"\ndata = {x.split('/')[-1].split('.')[0] : pd.read_csv(x, encoding=\"latin-1\") for x in glob.glob(Path)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:00:32.587551Z","iopub.execute_input":"2025-03-02T12:00:32.587768Z","iopub.status.idle":"2025-03-02T12:00:34.629111Z","shell.execute_reply.started":"2025-03-02T12:00:32.587746Z","shell.execute_reply":"2025-03-02T12:00:34.628225Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"MTeams = data['MTeams']\nWTeams = data['WTeams']\n\nMTeamSpellings = data['MTeamSpellings']\nWTeamSpellings = data['WTeamSpellings']\n\nMRegularSeasonCompactResults = data['MRegularSeasonCompactResults']\nWRegularSeasonCompactResults = data['WRegularSeasonCompactResults']\n\nMRegularSeasonDetailedResults = data['MRegularSeasonDetailedResults']\nWRegularSeasonDetailedResults = data['WRegularSeasonDetailedResults']\n\nMNCAATourneyCompactResults = data['MNCAATourneyCompactResults']\nWNCAATourneyCompactResults = data['WNCAATourneyCompactResults']\n\nMNCAATourneyDetailedResults = data['MNCAATourneyDetailedResults']\nWNCAATourneyDetailedResults = data['WNCAATourneyDetailedResults']\n\nMGameCities = data['MGameCities']\nWGameCities = data['WGameCities']\n\nMSeasons = data['MSeasons']\nWSeasons = data['WSeasons']\n\nMNCAATourneySeeds = data['MNCAATourneySeeds']\nWNCAATourneySeeds = data['WNCAATourneySeeds']\n\nCities = data['Cities']\nSampleSub = data['SampleSubmissionStage2']\n\ndel data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:00:34.630719Z","iopub.execute_input":"2025-03-02T12:00:34.631015Z","iopub.status.idle":"2025-03-02T12:00:34.674597Z","shell.execute_reply.started":"2025-03-02T12:00:34.630993Z","shell.execute_reply":"2025-03-02T12:00:34.673175Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"**Feature Enginerring**","metadata":{}},{"cell_type":"code","source":"Teams = pd.concat([MTeams, WTeams])\nTeamSpelling = pd.concat([MTeamSpellings, WTeamSpellings])\nTeamSpelling = TeamSpelling.groupby(by=\"TeamID\", as_index=False)['TeamNameSpelling'].count()\nTeamSpelling.columns = ['TeamID', 'TeamNameCount']\nTeams = pd.merge(Teams, TeamSpelling, how='left', on=['TeamID'])\ndel TeamSpelling\n\nSeasonCompactResults = pd.concat([MRegularSeasonCompactResults, WRegularSeasonCompactResults])\nSeasonDetailedResults = pd.concat([MRegularSeasonDetailedResults, WRegularSeasonDetailedResults])\n\nTourneyCompactResults = pd.concat([MNCAATourneyCompactResults, WNCAATourneyCompactResults])\nTourneyDetailedResults = pd.concat([MNCAATourneyDetailedResults, WNCAATourneyDetailedResults])\n\nGameCities = pd.concat([MGameCities, WGameCities])\nSeasons = pd.concat([MSeasons,WSeasons])\nSeeds = pd.concat([MNCAATourneySeeds, WNCAATourneySeeds])\n\nSeeds = {'_'.join(map(str, [int (x1), x2])): int(v[1:3])  for x1, v, x2 in Seeds[['Season', 'Seed', 'TeamID']].values}\n\nSeasonCompactResults['ST'] = 'S'\nSeasonDetailedResults['ST'] = 'S'\nTourneyCompactResults['ST'] = 'T'\nTourneyDetailedResults['ST'] = 'T'\n\nGames = pd.concat((SeasonDetailedResults,TourneyDetailedResults), axis=0, ignore_index=True)\nGames.reset_index(drop=True, inplace=True)\nGames['WLoc'] = Games['WLoc'].map({'H': 0, 'A': 1, 'N': 2})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:00:34.676218Z","iopub.execute_input":"2025-03-02T12:00:34.676552Z","iopub.status.idle":"2025-03-02T12:00:34.744518Z","shell.execute_reply.started":"2025-03-02T12:00:34.676526Z","shell.execute_reply":"2025-03-02T12:00:34.743734Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"Games['ID'] = Games.apply(lambda x: '_'.join(map(str, [x['Season']]+sorted([x['WTeamID'], x['LTeamID']]))), axis=1)\nGames['IDTeams'] = Games.apply(lambda x: '_'.join(map(str, sorted([x['WTeamID'], x['LTeamID']]))), axis=1)\nGames['Team1'] = Games.apply(lambda x:  sorted([x['WTeamID'], x['LTeamID']])[0], axis=1)\nGames['Team2'] = Games.apply(lambda x: sorted([x['WTeamID'], x['LTeamID']])[1], axis=1)\nGames['IDTeam1'] = Games.apply(lambda x: '_'.join(map(str, [x['Season'], x['Team1']])), axis=1)\nGames['IDTeam2'] = Games.apply(lambda x: '_'.join(map(str, [x['Season'], x['Team2']])), axis=1)\n\nGames['Team1Seed'] = Games['IDTeam1'].map(Seeds).fillna(0)\nGames['Team2Seed'] = Games['IDTeam2'].map(Seeds).fillna(0)\n\n# Games['Score_Difference'] = Games['WScore'] - Games['LScore']\nGames['Pred'] = Games.apply(lambda x: 1.0 if sorted([x['WTeamID'], x['LTeamID']])[0] == x['WTeamID'] else 0.0 , axis=1)\n# Games['ScoreDifferenceNorm'] = Games.apply(lambda x: x['Score_Difference'] * -1 if x['Pred'] == 0.0 \n#                                            else x['Score_Difference'], axis=1)\nGames['SeedDifference'] = Games['Team1Seed'] - Games['Team2Seed']\n\ncolumns = ['NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst', 'WTO', 'WStl',\n 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA', 'LOR', 'LDR', 'LAst', 'LTO', 'LStl',\n 'LBlk', 'LPF']\nagg = ['sum', 'mean', 'median', 'max', 'min', 'std', 'skew', 'nunique']\ngb = Games.groupby(by=('IDTeams')).agg({x: agg for x in columns }).reset_index()\ngb.columns = [''.join(x) + '_score' for x in gb.columns]\nGames = Games[Games['ST'] == 'T']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:00:34.745189Z","iopub.execute_input":"2025-03-02T12:00:34.745369Z","iopub.status.idle":"2025-03-02T12:00:45.665731Z","shell.execute_reply.started":"2025-03-02T12:00:34.745353Z","shell.execute_reply":"2025-03-02T12:00:45.664619Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"SampleSub['WLoc'] = 3\nSampleSub['Season'] = SampleSub['ID'].map(lambda x: x.split('_')[0])\nSampleSub['Season'] = SampleSub['Season'].astype(int)\nSampleSub['Team1'] = SampleSub['ID'].map(lambda x: x.split('_')[1])\nSampleSub['Team2'] = SampleSub['ID'].map(lambda x: x.split('_')[2])\nSampleSub['IDTeams'] = SampleSub.apply(lambda x: '_'.join(map(str, [x['Team1'], x['Team2']])), axis=1)\nSampleSub['IDTeam1'] = SampleSub.apply(lambda x: '_'.join(map(str, [x['Season'], x['Team1']])), axis=1)\nSampleSub['IDTeam2'] = SampleSub.apply(lambda x: '_'.join(map(str, [x['Season'], x['Team2']])), axis=1)\nSampleSub['Team1Seed'] = SampleSub['IDTeam1'].map(Seeds).fillna(0)\nSampleSub['Team2Seed'] = SampleSub['IDTeam2'].map(Seeds).fillna(0)\nSampleSub['SeedDifference'] = SampleSub['Team1Seed'] - SampleSub['Team2Seed']\n\n\nGames = pd.merge(Games,gb, how='left', left_on='IDTeams', right_on='IDTeams_score')\nSampleSub = pd.merge(SampleSub, gb, how='left', left_on='IDTeams', right_on='IDTeams_score')\nGames = Games.fillna(-1)\nSampleSub = SampleSub.fillna(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:00:45.666864Z","iopub.execute_input":"2025-03-02T12:00:45.667263Z","iopub.status.idle":"2025-03-02T12:00:48.640476Z","shell.execute_reply.started":"2025-03-02T12:00:45.667226Z","shell.execute_reply":"2025-03-02T12:00:48.639505Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"**Training and Testing Data**","metadata":{}},{"cell_type":"code","source":"cols = [c for c in Games.columns if c not in ['ID', 'DayNum', 'ST', 'Team1', 'Team2', 'IDTeams', 'IDTeam1', 'IDTeam2',\n                                             'WTeamID', 'WScore', 'LTeamID', 'LScore', 'NumOT', 'Pred', 'ScoreDiff', 'ScoreDiffNorm',\n                                             'WLoc'] + columns]\n\ntrain = Games[cols]\nX = train.drop(columns=['Pred'], errors='ignore')\nY = Games['Pred']\ntest = SampleSub[cols] ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:00:48.641431Z","iopub.execute_input":"2025-03-02T12:00:48.641730Z","iopub.status.idle":"2025-03-02T12:00:48.690407Z","shell.execute_reply.started":"2025-03-02T12:00:48.641702Z","shell.execute_reply":"2025-03-02T12:00:48.689615Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"> **Standardize the data**","metadata":{}},{"cell_type":"code","source":"Scaler = StandardScaler()\nX_scaled = Scaler.fit_transform(X)\nX_test = Scaler.transform(test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:00:48.692125Z","iopub.execute_input":"2025-03-02T12:00:48.692308Z","iopub.status.idle":"2025-03-02T12:00:52.361176Z","shell.execute_reply.started":"2025-03-02T12:00:48.692291Z","shell.execute_reply":"2025-03-02T12:00:52.360432Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def objective(trial):\n    params = {\n        'n_estimators': trial.suggest_int('n_estimators', 200, 1000),\n        'max_depth': trial.suggest_int('max_depth', 3, 20),\n        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 2, 20),\n        'max_features': trial.suggest_float('max_features', 0.3, 1.0),\n        # Fixed parameters\n        'criterion': 'squared_error',\n        'bootstrap': True,\n        'verbose': 0,\n        'random_state': 42\n    }\n\n    RandomForestModel = RandomForestRegressor(**params)\n    Error = []\n    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n    for train_idx, test_idx in kfold.split(X_scaled, Y):\n        X_train = X_scaled[train_idx]\n        X_test = X_scaled[test_idx]\n        Y_train = Y[train_idx]\n        Y_test = Y[test_idx]\n\n        model = clone(RandomForestModel)\n        model.fit(X_train, Y_train)\n        pred = model.predict(X_test)\n        error = mean_squared_error(Y_test, pred)\n        Error.append(error)\n\n    return np.mean(Error)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:00:52.362037Z","iopub.execute_input":"2025-03-02T12:00:52.362272Z","iopub.status.idle":"2025-03-02T12:00:52.368683Z","shell.execute_reply.started":"2025-03-02T12:00:52.362251Z","shell.execute_reply":"2025-03-02T12:00:52.367358Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# study = optuna.create_study(direction='minimize')\n# study.optimize(objective, n_trials=50)\n# print(study.best_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:00:52.369618Z","iopub.execute_input":"2025-03-02T12:00:52.369878Z","iopub.status.idle":"2025-03-02T12:00:52.398541Z","shell.execute_reply.started":"2025-03-02T12:00:52.369852Z","shell.execute_reply":"2025-03-02T12:00:52.397446Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"params = {'n_estimators': 1438, 'max_depth': 11,\n'min_samples_split': 8, 'min_samples_leaf': 27, 'max_features': 0.6005630225311747}\n\nModel = RandomForestRegressor(random_state=42, **params)\nModel.fit(X_scaled, Y)\npred = Model.predict(X_test)\n\nResult = pd.DataFrame({\n    'ID': SampleSub['ID'],\n    'Pred': pred\n})\nResult.to_csv('Predictions.csv', index=False)\nprint(\"Submission File Saved Successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-02T12:00:52.399855Z","iopub.execute_input":"2025-03-02T12:00:52.400277Z","iopub.status.idle":"2025-03-02T12:01:52.670464Z","shell.execute_reply.started":"2025-03-02T12:00:52.400243Z","shell.execute_reply":"2025-03-02T12:01:52.669696Z"}},"outputs":[],"execution_count":23}]}